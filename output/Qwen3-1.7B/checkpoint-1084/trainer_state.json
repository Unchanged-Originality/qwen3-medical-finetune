{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 100,
  "global_step": 1084,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018467220683287166,
      "grad_norm": 5.271783828735352,
      "learning_rate": 9.916974169741698e-06,
      "loss": 1.9985,
      "step": 10
    },
    {
      "epoch": 0.03693444136657433,
      "grad_norm": 4.028254508972168,
      "learning_rate": 9.824723247232474e-06,
      "loss": 1.8726,
      "step": 20
    },
    {
      "epoch": 0.055401662049861494,
      "grad_norm": 2.4903383255004883,
      "learning_rate": 9.732472324723247e-06,
      "loss": 1.656,
      "step": 30
    },
    {
      "epoch": 0.07386888273314866,
      "grad_norm": 2.1017017364501953,
      "learning_rate": 9.640221402214022e-06,
      "loss": 1.6279,
      "step": 40
    },
    {
      "epoch": 0.09233610341643583,
      "grad_norm": 1.4627439975738525,
      "learning_rate": 9.547970479704798e-06,
      "loss": 1.5103,
      "step": 50
    },
    {
      "epoch": 0.11080332409972299,
      "grad_norm": 1.1247707605361938,
      "learning_rate": 9.455719557195573e-06,
      "loss": 1.4605,
      "step": 60
    },
    {
      "epoch": 0.12927054478301014,
      "grad_norm": 0.9139184355735779,
      "learning_rate": 9.363468634686348e-06,
      "loss": 1.433,
      "step": 70
    },
    {
      "epoch": 0.14773776546629733,
      "grad_norm": 1.0027490854263306,
      "learning_rate": 9.271217712177123e-06,
      "loss": 1.3608,
      "step": 80
    },
    {
      "epoch": 0.16620498614958448,
      "grad_norm": 0.8115856051445007,
      "learning_rate": 9.178966789667897e-06,
      "loss": 1.3749,
      "step": 90
    },
    {
      "epoch": 0.18467220683287167,
      "grad_norm": 0.8616878986358643,
      "learning_rate": 9.086715867158672e-06,
      "loss": 1.3581,
      "step": 100
    },
    {
      "epoch": 0.18467220683287167,
      "eval_loss": 1.3678079843521118,
      "eval_runtime": 20.1011,
      "eval_samples_per_second": 11.989,
      "eval_steps_per_second": 11.989,
      "step": 100
    },
    {
      "epoch": 0.20313942751615882,
      "grad_norm": 0.8184469938278198,
      "learning_rate": 8.994464944649447e-06,
      "loss": 1.3493,
      "step": 110
    },
    {
      "epoch": 0.22160664819944598,
      "grad_norm": 0.8727400898933411,
      "learning_rate": 8.902214022140222e-06,
      "loss": 1.3596,
      "step": 120
    },
    {
      "epoch": 0.24007386888273316,
      "grad_norm": 0.7606518268585205,
      "learning_rate": 8.809963099630998e-06,
      "loss": 1.3688,
      "step": 130
    },
    {
      "epoch": 0.2585410895660203,
      "grad_norm": 0.8535298109054565,
      "learning_rate": 8.717712177121773e-06,
      "loss": 1.3211,
      "step": 140
    },
    {
      "epoch": 0.2770083102493075,
      "grad_norm": 0.782062828540802,
      "learning_rate": 8.625461254612546e-06,
      "loss": 1.2969,
      "step": 150
    },
    {
      "epoch": 0.29547553093259465,
      "grad_norm": 1.0578871965408325,
      "learning_rate": 8.533210332103322e-06,
      "loss": 1.3541,
      "step": 160
    },
    {
      "epoch": 0.3139427516158818,
      "grad_norm": 0.8313742280006409,
      "learning_rate": 8.440959409594097e-06,
      "loss": 1.3622,
      "step": 170
    },
    {
      "epoch": 0.33240997229916897,
      "grad_norm": 0.8068819046020508,
      "learning_rate": 8.34870848708487e-06,
      "loss": 1.3152,
      "step": 180
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 1.0269478559494019,
      "learning_rate": 8.256457564575646e-06,
      "loss": 1.3432,
      "step": 190
    },
    {
      "epoch": 0.36934441366574333,
      "grad_norm": 0.9530159831047058,
      "learning_rate": 8.16420664206642e-06,
      "loss": 1.3208,
      "step": 200
    },
    {
      "epoch": 0.36934441366574333,
      "eval_loss": 1.3191230297088623,
      "eval_runtime": 18.9354,
      "eval_samples_per_second": 12.727,
      "eval_steps_per_second": 12.727,
      "step": 200
    },
    {
      "epoch": 0.3878116343490305,
      "grad_norm": 0.8811867237091064,
      "learning_rate": 8.071955719557196e-06,
      "loss": 1.2966,
      "step": 210
    },
    {
      "epoch": 0.40627885503231764,
      "grad_norm": 0.8728848695755005,
      "learning_rate": 7.979704797047971e-06,
      "loss": 1.304,
      "step": 220
    },
    {
      "epoch": 0.4247460757156048,
      "grad_norm": 1.0231492519378662,
      "learning_rate": 7.887453874538746e-06,
      "loss": 1.2858,
      "step": 230
    },
    {
      "epoch": 0.44321329639889195,
      "grad_norm": 0.9258174896240234,
      "learning_rate": 7.795202952029522e-06,
      "loss": 1.3111,
      "step": 240
    },
    {
      "epoch": 0.4616805170821791,
      "grad_norm": 1.0107269287109375,
      "learning_rate": 7.702952029520295e-06,
      "loss": 1.3148,
      "step": 250
    },
    {
      "epoch": 0.4801477377654663,
      "grad_norm": 0.9579896926879883,
      "learning_rate": 7.6107011070110704e-06,
      "loss": 1.2941,
      "step": 260
    },
    {
      "epoch": 0.4986149584487535,
      "grad_norm": 0.83672034740448,
      "learning_rate": 7.518450184501846e-06,
      "loss": 1.3014,
      "step": 270
    },
    {
      "epoch": 0.5170821791320406,
      "grad_norm": 0.9678016304969788,
      "learning_rate": 7.42619926199262e-06,
      "loss": 1.2506,
      "step": 280
    },
    {
      "epoch": 0.5355493998153278,
      "grad_norm": 0.9555585384368896,
      "learning_rate": 7.333948339483395e-06,
      "loss": 1.2802,
      "step": 290
    },
    {
      "epoch": 0.554016620498615,
      "grad_norm": 0.8939975500106812,
      "learning_rate": 7.2416974169741705e-06,
      "loss": 1.2958,
      "step": 300
    },
    {
      "epoch": 0.554016620498615,
      "eval_loss": 1.2983280420303345,
      "eval_runtime": 18.4034,
      "eval_samples_per_second": 13.095,
      "eval_steps_per_second": 13.095,
      "step": 300
    },
    {
      "epoch": 0.5724838411819021,
      "grad_norm": 0.9534600973129272,
      "learning_rate": 7.149446494464946e-06,
      "loss": 1.2791,
      "step": 310
    },
    {
      "epoch": 0.5909510618651893,
      "grad_norm": 0.9340031743049622,
      "learning_rate": 7.057195571955721e-06,
      "loss": 1.3121,
      "step": 320
    },
    {
      "epoch": 0.6094182825484764,
      "grad_norm": 0.8289255499839783,
      "learning_rate": 6.9649446494464944e-06,
      "loss": 1.2894,
      "step": 330
    },
    {
      "epoch": 0.6278855032317636,
      "grad_norm": 1.0945320129394531,
      "learning_rate": 6.87269372693727e-06,
      "loss": 1.3366,
      "step": 340
    },
    {
      "epoch": 0.6463527239150508,
      "grad_norm": 0.9243929982185364,
      "learning_rate": 6.780442804428045e-06,
      "loss": 1.2959,
      "step": 350
    },
    {
      "epoch": 0.6648199445983379,
      "grad_norm": 1.175494909286499,
      "learning_rate": 6.688191881918819e-06,
      "loss": 1.2752,
      "step": 360
    },
    {
      "epoch": 0.6832871652816251,
      "grad_norm": 0.9283306002616882,
      "learning_rate": 6.5959409594095945e-06,
      "loss": 1.2614,
      "step": 370
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.9823709726333618,
      "learning_rate": 6.50369003690037e-06,
      "loss": 1.2939,
      "step": 380
    },
    {
      "epoch": 0.7202216066481995,
      "grad_norm": 1.027158260345459,
      "learning_rate": 6.411439114391145e-06,
      "loss": 1.2874,
      "step": 390
    },
    {
      "epoch": 0.7386888273314867,
      "grad_norm": 1.0263231992721558,
      "learning_rate": 6.31918819188192e-06,
      "loss": 1.2583,
      "step": 400
    },
    {
      "epoch": 0.7386888273314867,
      "eval_loss": 1.2866030931472778,
      "eval_runtime": 20.8171,
      "eval_samples_per_second": 11.577,
      "eval_steps_per_second": 11.577,
      "step": 400
    },
    {
      "epoch": 0.7571560480147738,
      "grad_norm": 0.9721778035163879,
      "learning_rate": 6.226937269372694e-06,
      "loss": 1.2523,
      "step": 410
    },
    {
      "epoch": 0.775623268698061,
      "grad_norm": 0.9587253332138062,
      "learning_rate": 6.134686346863469e-06,
      "loss": 1.2736,
      "step": 420
    },
    {
      "epoch": 0.7940904893813481,
      "grad_norm": 0.9236088395118713,
      "learning_rate": 6.042435424354244e-06,
      "loss": 1.3018,
      "step": 430
    },
    {
      "epoch": 0.8125577100646353,
      "grad_norm": 1.0361772775650024,
      "learning_rate": 5.9501845018450185e-06,
      "loss": 1.3019,
      "step": 440
    },
    {
      "epoch": 0.8310249307479224,
      "grad_norm": 0.9507050514221191,
      "learning_rate": 5.857933579335794e-06,
      "loss": 1.3223,
      "step": 450
    },
    {
      "epoch": 0.8494921514312096,
      "grad_norm": 1.0188004970550537,
      "learning_rate": 5.765682656826569e-06,
      "loss": 1.2647,
      "step": 460
    },
    {
      "epoch": 0.8679593721144968,
      "grad_norm": 0.9381237626075745,
      "learning_rate": 5.673431734317344e-06,
      "loss": 1.2902,
      "step": 470
    },
    {
      "epoch": 0.8864265927977839,
      "grad_norm": 1.0730767250061035,
      "learning_rate": 5.581180811808119e-06,
      "loss": 1.2799,
      "step": 480
    },
    {
      "epoch": 0.9048938134810711,
      "grad_norm": 1.0070223808288574,
      "learning_rate": 5.488929889298893e-06,
      "loss": 1.2902,
      "step": 490
    },
    {
      "epoch": 0.9233610341643582,
      "grad_norm": 1.0215712785720825,
      "learning_rate": 5.396678966789668e-06,
      "loss": 1.3335,
      "step": 500
    },
    {
      "epoch": 0.9233610341643582,
      "eval_loss": 1.278498649597168,
      "eval_runtime": 17.7522,
      "eval_samples_per_second": 13.576,
      "eval_steps_per_second": 13.576,
      "step": 500
    },
    {
      "epoch": 0.9418282548476454,
      "grad_norm": 1.1984648704528809,
      "learning_rate": 5.304428044280443e-06,
      "loss": 1.2984,
      "step": 510
    },
    {
      "epoch": 0.9602954755309326,
      "grad_norm": 0.935329794883728,
      "learning_rate": 5.212177121771218e-06,
      "loss": 1.2625,
      "step": 520
    },
    {
      "epoch": 0.9787626962142197,
      "grad_norm": 1.0034372806549072,
      "learning_rate": 5.119926199261993e-06,
      "loss": 1.3056,
      "step": 530
    },
    {
      "epoch": 0.997229916897507,
      "grad_norm": 0.9888603687286377,
      "learning_rate": 5.027675276752768e-06,
      "loss": 1.3025,
      "step": 540
    },
    {
      "epoch": 1.0147737765466298,
      "grad_norm": 1.0043598413467407,
      "learning_rate": 4.9354243542435426e-06,
      "loss": 1.2353,
      "step": 550
    },
    {
      "epoch": 1.0332409972299168,
      "grad_norm": 1.1117252111434937,
      "learning_rate": 4.843173431734318e-06,
      "loss": 1.3016,
      "step": 560
    },
    {
      "epoch": 1.051708217913204,
      "grad_norm": 1.2966160774230957,
      "learning_rate": 4.750922509225093e-06,
      "loss": 1.2323,
      "step": 570
    },
    {
      "epoch": 1.0701754385964912,
      "grad_norm": 1.0476081371307373,
      "learning_rate": 4.658671586715867e-06,
      "loss": 1.255,
      "step": 580
    },
    {
      "epoch": 1.0886426592797784,
      "grad_norm": 0.9929305911064148,
      "learning_rate": 4.566420664206643e-06,
      "loss": 1.2828,
      "step": 590
    },
    {
      "epoch": 1.1071098799630656,
      "grad_norm": 1.209877371788025,
      "learning_rate": 4.474169741697417e-06,
      "loss": 1.2588,
      "step": 600
    },
    {
      "epoch": 1.1071098799630656,
      "eval_loss": 1.2726086378097534,
      "eval_runtime": 17.3883,
      "eval_samples_per_second": 13.86,
      "eval_steps_per_second": 13.86,
      "step": 600
    },
    {
      "epoch": 1.1255771006463526,
      "grad_norm": 1.022000789642334,
      "learning_rate": 4.381918819188192e-06,
      "loss": 1.2305,
      "step": 610
    },
    {
      "epoch": 1.1440443213296398,
      "grad_norm": 1.023942232131958,
      "learning_rate": 4.289667896678967e-06,
      "loss": 1.264,
      "step": 620
    },
    {
      "epoch": 1.162511542012927,
      "grad_norm": 1.0181595087051392,
      "learning_rate": 4.197416974169742e-06,
      "loss": 1.2569,
      "step": 630
    },
    {
      "epoch": 1.1809787626962143,
      "grad_norm": 0.9224075078964233,
      "learning_rate": 4.105166051660517e-06,
      "loss": 1.2689,
      "step": 640
    },
    {
      "epoch": 1.1994459833795015,
      "grad_norm": 1.1427756547927856,
      "learning_rate": 4.012915129151292e-06,
      "loss": 1.26,
      "step": 650
    },
    {
      "epoch": 1.2179132040627885,
      "grad_norm": 1.0062475204467773,
      "learning_rate": 3.920664206642067e-06,
      "loss": 1.2542,
      "step": 660
    },
    {
      "epoch": 1.2363804247460757,
      "grad_norm": 1.0291414260864258,
      "learning_rate": 3.828413284132842e-06,
      "loss": 1.2664,
      "step": 670
    },
    {
      "epoch": 1.254847645429363,
      "grad_norm": 1.0446555614471436,
      "learning_rate": 3.7361623616236166e-06,
      "loss": 1.2532,
      "step": 680
    },
    {
      "epoch": 1.27331486611265,
      "grad_norm": 1.0605839490890503,
      "learning_rate": 3.6439114391143914e-06,
      "loss": 1.262,
      "step": 690
    },
    {
      "epoch": 1.291782086795937,
      "grad_norm": 0.9360865354537964,
      "learning_rate": 3.5516605166051667e-06,
      "loss": 1.2792,
      "step": 700
    },
    {
      "epoch": 1.291782086795937,
      "eval_loss": 1.268561601638794,
      "eval_runtime": 17.3908,
      "eval_samples_per_second": 13.858,
      "eval_steps_per_second": 13.858,
      "step": 700
    },
    {
      "epoch": 1.3102493074792243,
      "grad_norm": 0.9491695761680603,
      "learning_rate": 3.459409594095941e-06,
      "loss": 1.2847,
      "step": 710
    },
    {
      "epoch": 1.3287165281625115,
      "grad_norm": 0.9939925074577332,
      "learning_rate": 3.3671586715867163e-06,
      "loss": 1.2521,
      "step": 720
    },
    {
      "epoch": 1.3471837488457987,
      "grad_norm": 1.1553800106048584,
      "learning_rate": 3.274907749077491e-06,
      "loss": 1.2622,
      "step": 730
    },
    {
      "epoch": 1.365650969529086,
      "grad_norm": 1.13013756275177,
      "learning_rate": 3.1826568265682663e-06,
      "loss": 1.2809,
      "step": 740
    },
    {
      "epoch": 1.384118190212373,
      "grad_norm": 1.0893293619155884,
      "learning_rate": 3.0904059040590406e-06,
      "loss": 1.2842,
      "step": 750
    },
    {
      "epoch": 1.4025854108956601,
      "grad_norm": 0.9452670812606812,
      "learning_rate": 2.998154981549816e-06,
      "loss": 1.2927,
      "step": 760
    },
    {
      "epoch": 1.4210526315789473,
      "grad_norm": 1.122982382774353,
      "learning_rate": 2.9059040590405907e-06,
      "loss": 1.2871,
      "step": 770
    },
    {
      "epoch": 1.4395198522622346,
      "grad_norm": 1.167718768119812,
      "learning_rate": 2.813653136531366e-06,
      "loss": 1.2279,
      "step": 780
    },
    {
      "epoch": 1.4579870729455218,
      "grad_norm": 0.9001737236976624,
      "learning_rate": 2.7214022140221403e-06,
      "loss": 1.2367,
      "step": 790
    },
    {
      "epoch": 1.4764542936288088,
      "grad_norm": 1.0367074012756348,
      "learning_rate": 2.629151291512915e-06,
      "loss": 1.2669,
      "step": 800
    },
    {
      "epoch": 1.4764542936288088,
      "eval_loss": 1.265557050704956,
      "eval_runtime": 17.7115,
      "eval_samples_per_second": 13.607,
      "eval_steps_per_second": 13.607,
      "step": 800
    },
    {
      "epoch": 1.494921514312096,
      "grad_norm": 1.0029354095458984,
      "learning_rate": 2.5369003690036903e-06,
      "loss": 1.2492,
      "step": 810
    },
    {
      "epoch": 1.5133887349953832,
      "grad_norm": 1.1824084520339966,
      "learning_rate": 2.444649446494465e-06,
      "loss": 1.2699,
      "step": 820
    },
    {
      "epoch": 1.5318559556786704,
      "grad_norm": 1.026390552520752,
      "learning_rate": 2.3523985239852403e-06,
      "loss": 1.2561,
      "step": 830
    },
    {
      "epoch": 1.5503231763619576,
      "grad_norm": 1.1031825542449951,
      "learning_rate": 2.2601476014760147e-06,
      "loss": 1.2365,
      "step": 840
    },
    {
      "epoch": 1.5687903970452446,
      "grad_norm": 1.2072237730026245,
      "learning_rate": 2.16789667896679e-06,
      "loss": 1.2587,
      "step": 850
    },
    {
      "epoch": 1.587257617728532,
      "grad_norm": 0.97959303855896,
      "learning_rate": 2.0756457564575647e-06,
      "loss": 1.2794,
      "step": 860
    },
    {
      "epoch": 1.605724838411819,
      "grad_norm": 0.9377161264419556,
      "learning_rate": 1.9833948339483395e-06,
      "loss": 1.207,
      "step": 870
    },
    {
      "epoch": 1.6241920590951062,
      "grad_norm": 1.2186224460601807,
      "learning_rate": 1.8911439114391145e-06,
      "loss": 1.2632,
      "step": 880
    },
    {
      "epoch": 1.6426592797783934,
      "grad_norm": 1.1176267862319946,
      "learning_rate": 1.7988929889298895e-06,
      "loss": 1.2393,
      "step": 890
    },
    {
      "epoch": 1.6611265004616804,
      "grad_norm": 1.143435001373291,
      "learning_rate": 1.7066420664206643e-06,
      "loss": 1.246,
      "step": 900
    },
    {
      "epoch": 1.6611265004616804,
      "eval_loss": 1.2634831666946411,
      "eval_runtime": 17.4747,
      "eval_samples_per_second": 13.791,
      "eval_steps_per_second": 13.791,
      "step": 900
    },
    {
      "epoch": 1.6795937211449676,
      "grad_norm": 1.1643505096435547,
      "learning_rate": 1.6143911439114393e-06,
      "loss": 1.2958,
      "step": 910
    },
    {
      "epoch": 1.6980609418282548,
      "grad_norm": 1.0970722436904907,
      "learning_rate": 1.5221402214022141e-06,
      "loss": 1.2536,
      "step": 920
    },
    {
      "epoch": 1.716528162511542,
      "grad_norm": 1.1251330375671387,
      "learning_rate": 1.4298892988929891e-06,
      "loss": 1.2662,
      "step": 930
    },
    {
      "epoch": 1.7349953831948293,
      "grad_norm": 1.0310847759246826,
      "learning_rate": 1.337638376383764e-06,
      "loss": 1.2428,
      "step": 940
    },
    {
      "epoch": 1.7534626038781163,
      "grad_norm": 1.0992069244384766,
      "learning_rate": 1.245387453874539e-06,
      "loss": 1.2545,
      "step": 950
    },
    {
      "epoch": 1.7719298245614035,
      "grad_norm": 1.1145625114440918,
      "learning_rate": 1.1531365313653137e-06,
      "loss": 1.2545,
      "step": 960
    },
    {
      "epoch": 1.7903970452446907,
      "grad_norm": 1.159948706626892,
      "learning_rate": 1.0608856088560888e-06,
      "loss": 1.2536,
      "step": 970
    },
    {
      "epoch": 1.8088642659279779,
      "grad_norm": 1.0356309413909912,
      "learning_rate": 9.686346863468636e-07,
      "loss": 1.2494,
      "step": 980
    },
    {
      "epoch": 1.827331486611265,
      "grad_norm": 1.178044080734253,
      "learning_rate": 8.763837638376385e-07,
      "loss": 1.2607,
      "step": 990
    },
    {
      "epoch": 1.845798707294552,
      "grad_norm": 1.0948587656021118,
      "learning_rate": 7.841328413284134e-07,
      "loss": 1.2531,
      "step": 1000
    },
    {
      "epoch": 1.845798707294552,
      "eval_loss": 1.2623802423477173,
      "eval_runtime": 17.3592,
      "eval_samples_per_second": 13.883,
      "eval_steps_per_second": 13.883,
      "step": 1000
    },
    {
      "epoch": 1.8642659279778393,
      "grad_norm": 1.264245867729187,
      "learning_rate": 6.918819188191883e-07,
      "loss": 1.2576,
      "step": 1010
    },
    {
      "epoch": 1.8827331486611265,
      "grad_norm": 1.1085920333862305,
      "learning_rate": 5.996309963099632e-07,
      "loss": 1.2734,
      "step": 1020
    },
    {
      "epoch": 1.9012003693444137,
      "grad_norm": 1.1312477588653564,
      "learning_rate": 5.073800738007381e-07,
      "loss": 1.2869,
      "step": 1030
    },
    {
      "epoch": 1.919667590027701,
      "grad_norm": 1.0591336488723755,
      "learning_rate": 4.1512915129151293e-07,
      "loss": 1.24,
      "step": 1040
    },
    {
      "epoch": 1.938134810710988,
      "grad_norm": 1.0404016971588135,
      "learning_rate": 3.2287822878228783e-07,
      "loss": 1.2141,
      "step": 1050
    },
    {
      "epoch": 1.9566020313942751,
      "grad_norm": 0.9988722205162048,
      "learning_rate": 2.3062730627306274e-07,
      "loss": 1.2631,
      "step": 1060
    },
    {
      "epoch": 1.9750692520775623,
      "grad_norm": 1.1532533168792725,
      "learning_rate": 1.3837638376383764e-07,
      "loss": 1.3098,
      "step": 1070
    },
    {
      "epoch": 1.9935364727608493,
      "grad_norm": 1.0343579053878784,
      "learning_rate": 4.612546125461255e-08,
      "loss": 1.2531,
      "step": 1080
    }
  ],
  "logging_steps": 10,
  "max_steps": 1084,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 400,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.96559997510656e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
